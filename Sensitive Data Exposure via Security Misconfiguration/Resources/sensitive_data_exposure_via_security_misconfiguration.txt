We look for the existence of robots.txt file which helps search engines to decide which paths in our site can be crawled. And find:

User-agent: *
Disallow: /whatever
Disallow: /.hidden

At /robots.txt we look inside /whatever path and going there we find a publicly accessible htpasswd file with the following content:

root:437394baff5aa33daa618be47b75cb49

We identify the hash as MD5 with the value qwerty123@

With this discovered credentials, we realize there is an /admin path asking for a username and password

We login at /admin with username root and password qwerty123@ and get the flag

------------------------------------------------------------------------------------

Mitigating this attack sensitive data misconfiguration:

- Review the server configuration to deny access to these files.
- Avoid placing sensitive files in public directories, .htpasswd should not be within the Web server's URI space -- that is, they should not be fetchable with a browser.
- Do not add sensitive paths to the robots configuration.

Notes:

The robots.txt file is a standard used to communicate with web crawlers and other web robots.
It allows website administrators to define rules about which parts of the site should not be crawled or indexed.
However, these rules are merely advisory and should not be relied upon to protect sensitive resources, as they can easily be read by anyone.

The .htpasswd file is used in combination with .htaccess to enforce basic HTTP authentication on Apache servers.
It contains username and hashed password pairs.
This file should never be publicly accessible, as it may expose hashed credentials that can be cracked offline.
